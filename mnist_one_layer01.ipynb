{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-one-layer01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fevzidas/deeplearning/blob/master/mnist_one_layer01.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "TwDfRg87elox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9c0dd68f-3201-4016-a515-01ed3fa9a74f"
      },
      "cell_type": "code",
      "source": [
        "# Udemy Bölüm 4, Ders 15\n",
        "\n",
        "# Tensorflow Google tarafından otomatik olarak import edildiği için tekrar yazmıyoruz. \n",
        "# One host her bir sınıfın 0 ve 1 lerden oluşan bir vektör ile gösterilmesini sağlamaktadır.\n",
        "# Örneğin ağaç, ev, araba gibi 3 sınıf için\n",
        "# ağaç = [1,0,0], ev = [0,1,0] ve araba = [0,0,1] \n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('data/MNIST', one_hot=True)\n",
        "\n",
        "\n",
        "# Placeholder (Yer tutucu) tanımlama\n",
        "# Gelecek olan veriler float32 türündedir. \n",
        "# None kaç adet resim geleceğini belirtir.\n",
        "# 784 ise işlenecek her bir resmin vektöre dönüştürülmüş boyutu (28x28) \n",
        "# Placeholder şu anda boş\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "\n",
        "# İşlenecek tüm resimlerin labelleri vardır. Bu labeller için yer tutucu tanımluyoruz.\n",
        "# MNIST resimleri 0-9 aralığındaki toplam 10 adet rakamdan oluşmaktadır. Yani label sayısı 10 dur.\n",
        "# Dolayısıyla gerçek etiket değerlerini tutan y_true yer tutucusunun boyutu 10 olarak belirlenmiştir. \n",
        "y_true = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "# Genel formülümüz y = w.x + b şeklindeydi. Yukarıda x tanımlandı. \n",
        "# Şimdi sıra diğer değişkenlerde\n",
        "# Weight tanımı\n",
        "# Variable eğitilecek değerler olduğunu gösterir.\n",
        "# x ve w çarpımı yapabilmek için satır sütün sayısı eşit olmalıdır.\n",
        "# Mevcut durumda x = [None, 784] tür. \n",
        "# O halde w = [784, 10] olmalıdır. 10 nöron (sınıf) sayısını göstermektedir. \n",
        "# Örneğin x = 500 resim verildiğinde x=[500,784], w=[784,10] ve x*w=[500,10] olacaktır.\n",
        "# Yani 500 resmin her biri için ayrı ayrı 10 tahmin yapılacaktır.\n",
        "# Bu yapıda tek layerli bir network oluşturulmuştur.\n",
        "# Bu layersa 10 nöron vardır. Bu nöronlar her bir resim için sınıfı tahmin etmeye çalışacaktır. \n",
        "w = tf.Variable(tf.zeros([784, 10]))\n",
        "\n",
        "# Geriye bayes yani b kaldı.\n",
        "# 10 nöron olduğu için 10 değeri verildi.\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "# w.x + b ifadesine genel olarak logist denir.\n",
        "# w ve b ise optimize edilecek olan değerlerdir. Bu değerlere başlangıçta 0 değerleri verilmiştir.\n",
        "logits = tf.matmul(x, w) + b\n",
        "\n",
        "# logist değerini aktivasyon fonksiyonundn geçirme işlemi\n",
        "# softmax ile tüm değerler 0-1 aralığına sıkıştırılır.\n",
        "# Tüm değerlerin toplamı ise 1 dir. (olasılık gibi)\n",
        "# Tensorflowda aktivasyon fonksiyonları nn kütüphanesinde yer alır.\n",
        "# logits = [1.2, 0.6, -0.4, -0.2, 4.3, 0.1, 0.3, -0.1, 0.5, 0.7]\n",
        "# softmax(logits) = [0.04, 0.02, 0.01, 0.01, 0.84, 0.01, 0.02, 0.01, 0.02, 0.02]\n",
        "y = tf.nn.softmax(logits)\n",
        "\n",
        "\n",
        "# Şimdi modelin doğruluğunu kontrol edelim\n",
        "# Bunun için loss fonksiyonu kullanılır.\n",
        "# Bu çalışmada loss olarak cross entropy fonksiyonu kullanılacaktır.\n",
        "# Cross entropy iki parametre istemektedir. Birincisi tahmin edilen değer olan logits = tf.matmul(x, w) + b\n",
        "# İkincisi ise nesnelere ait gerçek sınıf değerlerini içeren labels değeri\n",
        "# Logist değeri olarak y yerine aktivasyon fonksiyonundan geçmemiş olan logits değeri verilecektir.\n",
        "# Çünkü cross entropy kendi içinde aktivasyon fonksiyonuna zaten sahiptir. \n",
        "xent = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_true)\n",
        "\n",
        "# xent ortalamaları alınacak olan değerleri içeren vektördür. \n",
        "# Örneğin batch size 128 ise bu durumda xent 128 değer tutan bir vektör demektir. \n",
        "loss = tf.reduce_mean(xent)\n",
        "\n",
        "# Modelin doğruluğunu hesaplama\n",
        "# y değeri tahmin edilen değeri y_true ise gerçek değer tutmaktadır\n",
        "# 1 değeri dimension (boyut) bilgisini verir\n",
        "# argmax fonksiyonu  en büyük değeri olan endeksi döndürür.\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_true, 1))\n",
        "\n",
        "#correct_prediction True ve False değerlerini içeren bir vekördür.\n",
        "# Bu vektöründeki değerlerin ortalamasını almak için cast ile tür dönüşümü yapılmalıdır.\n",
        "# Kullanımı cast(dönüştürülecek_değer, dönüştürülecek_tip)\n",
        "# reduce mean ise ortalama almaktadır. \n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# Optimizasyon işlemi\n",
        "# 0.5 learning rate \n",
        "optimize = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
        "\n",
        "# Bu kodları çalıştırmak için Oturum açılmalıdır\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Her yığında olması gereken resim sayısı\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# iterations kaç defa döngü dönüp eğitim yapılacağını belirtir.\n",
        "def training_step(iterations):\n",
        "  for i in range(iterations):\n",
        "    #MNIST data setinden belirlenen sayıda (batch_size) rastgelene resim alınmasını sağlar.\n",
        "    # x_batch resimleri, y_batch resimlere ait etiket (label) değerlerini tutar\n",
        "    x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "    feed_dict_train = {x: x_batch, y_true: y_batch}\n",
        "    sess.run(optimize, feed_dict=feed_dict_train)\n",
        "\n",
        "def test_accuracy():\n",
        "  feed_dict_test = {x:mnist.test.images, y_true:mnist.test.labels }\n",
        "  acc = sess.run(accuracy, feed_dict=feed_dict_test)\n",
        "  print('Testing accuracy : ', acc)\n",
        "\n",
        "\n",
        "training_step(600)\n",
        "test_accuracy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
            "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
            "Testing accuracy :  0.9174\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}